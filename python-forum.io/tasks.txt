
            Парсинг Форума https://python-forum.io          
------------------------------------------------------------
* Нужно сделать переходы по категориям на сайте
* В каждой категории распарсить вопросы переходя по страницам
* Что нужно распарсить:
    - название вопроса (title);
    - кол-во ответов (answer);
    - кол-во просмотров (views);
    - дата создания вопроса (date);
    - сам вопрос, только текст (question).


Есть 4 таблицы. Первые три с категориями. В таблице есть теги tbody.
В tbody есть теги tr и td, отвечающие за строки и столбцы.
Нам нужны td с класом trow1/trow2 в них содеожатся названия категорий, ссылка и информация.

find_all tbody class re(trow0-9)


Понедельник позвонить и договориться 

TODO
==============================
(?) Парсинг, сохранение и запись в файл вопросов (pickle)
Написать отдельную главную функцию с параметрами
Добавить исключения 
Создать таблицу с полями 
Сохранение в БД
Распарсить форум

(?) Отдельный файл работающий с БД
------------------------------
load() - загрузка с файла переменной
dump() - сохранение в файл переменной
save_to_db() - сохранение в бд


Как работает парсер Stackoverflow
---------------------------------

Soapi парсит основные данные заголовки, время, промотры и т.д.
Parseq парсит сами вопросы при помощи bs4.
В soapi данные сохраняются соразу в БД, а в parseq можно как в БД так и отдельно в файл. Помимо этого в для parseq есть отдельный скрипт сохраняющий из файла в БД.

Необходимо сделать сохранение в бд, и отдельно в файл (потом в бд) в написанном модуле (SaveDB), для того чтобы потом можно было использовать для последующих скриптов парсинга.

Как будет работать парсер форума1
---------------------------------

Указываю категорию и идёт парсинг этой категории вопросов постранично.
После каждой страницы возвращает список (или словарь) с данными.
Нужно сохранять каждую страницу и сделать проверку, если есть вопрос в БД, то пропускать.
Сохранение сразу в БД т.к. всё равно качает быстро и без блокировки.
В программе сделать главную функцию принимающие парамметры все качать или определённую категорию с определённой страницей.

Проблемы которые встретятся (или уже встречались) в парсерах.
-------------------------------------------------------------
* Сохранение времени (в каком формате, часовой пояс)
* Кодировка текстов (вопросов и заголовков, с сохранением неизвестной кодировки)
* В некоторых сайтах блокировка

Необходимо учесть при написании цельного парсера.
Писать ли единую программа для парсинга или парсить по отдельным сайтам.
Можно сначала написать все скрипты под каждый сайт. Далее распарсить все вопросы, и заниматься сайтом и отображением. После этого, если будет свободное время скомпоновать все скрипты в одну программу.

