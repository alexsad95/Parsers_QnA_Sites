
            Парсинг Форума https://python-forum.io          
------------------------------------------------------------
* Нужно сделать переходы по категориям на сайте
* В каждой категории распарсить вопросы переходя по страницам
* Что нужно распарсить:
    - название вопроса (title);
    - кол-во ответов (answer);
    - кол-во просмотров (views);
    - дата создания вопроса (date);
    - сам вопрос, только текст (question).


Есть 4 таблицы. Первые три с категориями. В таблице есть теги tbody.
В tbody есть теги tr и td, отвечающие за строки и столбцы.
Нам нужны td с класом trow1/trow2 в них содеожатся названия категорий, ссылка и информация.

find_all tbody class re(trow0-9)


Понедельник позвонить и договориться 

TODO
==============================
(?) Парсинг, сохранение и запись в файл вопросов (pickle)
Написать отдельную главную функцию с параметрами
Добавить исключения 
Создать таблицу с полями 
Сохранение в БД
Распарсить форум

(?) Отдельный файл работающий с БД
------------------------------
load() - загрузка с файла переменной
dump() - сохранение в файл переменной
save_to_db() - сохранение в бд


Как работает парсер Stackoverflow
---------------------------------

Soapi парсит основные данные заголовки, время, промотры и т.д.
Parseq парсит сами вопросы при помощи bs4.
В soapi данные сохраняются соразу в БД, а в parseq можно как в БД так и отдельно в файл. Помимо этого в для parseq есть отдельный скрипт сохраняющий из файла в БД.

Необходимо сделать сохранение в бд, и отдельно в файл (потом в бд) в написанном модуле (SaveDB), для того чтобы потом можно было использовать для последующих скриптов парсинга.

Как будет работать парсер форума1
---------------------------------

Указываю категорию и идёт парсинг этой категории вопросов постранично.
После каждой страницы возвращает список (или словарь) с данными.
Нужно сохранять каждую страницу и сделать проверку, если есть вопрос в БД, то пропускать.
Сохранение сразу в БД т.к. всё равно качает быстро и без блокировки.
В программе сделать главную функцию принимающие парамметры все качать или определённую категорию с определённой страницей.

Проблемы которые встретятся (или уже встречались) в парсерах.
-------------------------------------------------------------
* Сохранение времени (в каком формате, часовой пояс)
* Кодировка текстов (вопросов и заголовков, с сохранением неизвестной кодировки)
* В некоторых сайтах блокировка

Необходимо учесть при написании цельного парсера.
Писать ли единую программа для парсинга или парсить по отдельным сайтам.
Можно сначала написать все скрипты под каждый сайт. Далее распарсить все вопросы, и заниматься сайтом и отображением. После этого, если будет свободное время скомпоновать все скрипты в одну программу.


БД для сохранения данных с форума 
=================================
Нужно добавить поле для id
Поля БД:
  *id
  *title
  *href
  *question
  *answer
  *views
1 таблица основная, остальные под категории.
Названия как у категорий:
  *general_coding_help
  *homework
  *gui
  *game_development
  *networking
  *web_development
  *news_and_discussions
  *tutorials
  *completed_scripts/snippets
  *jobs
  *board
  *bar

Ошибка со парсингом Tutrials
------------------------------------------------
Traceback (most recent call last):
  File "forum1_3v.py", line 294, in <module>
    main_function(command)
  File "forum1_3v.py", line 273, in main_function
    for i in range(parse_count_pages(url)):
  File "forum1_3v.py", line 196, in parse_count_pages
    count = re.findall('\d+', str(div_pagination.span.text))
AttributeError: 'NoneType' object has no attribute 'span'

Такие ошибки в категориях:
Game Tutorials
Web Tutorials
GUI tutorials
Networking Tutorials 

===============================================
Варианты реализовать вывод книг и поиск по ним:
1) Написать/найти конвертер pdf в xml поиск и парсинг файлов xml далее вывод страниц
В зависимости от страницы вывод опред. главы, всю информацию по поиску вывести на сайт
Выбрать результат
Далее перенаправление на cтраницу в онлайн viewer-е pdf

Минус подхода:
Парсинг всех книг + файлы xml помимо pdf
Долгий поиск и вывод (возможно)
Разный парсинг под разные книги
2) Вывод pdf viewer-ом на странице.
Придумать как реализовать поискa



            PDF2TXT               
----------------------------------
Вариант с написанием парсера
[x] TODO --> Выбрать модуль для чтения pdf
[x] TODO ?-> Модуль для изменения pdf в XML 
[x] TODO --> Вывод xml текста определённой страницы
[x] TODO --> Вывод xml страниц
[x] TODO --> Сохранение pdf в файл
[ ] TODO --> Поиск по тексту

Плюсы
- Можно автоматизировать
Минусы найденой реализации/модуля
- Плохой парсинг текста (дробление слов)
- Отсутствие полной документации

Вариант с использованием Adobe и сохранением как текст
[ ] TODO --> Изменение метки на тег и номер страницы
[ ] TODO --> Вручную убрать не нужные метки (или попробовать написать скрипт)
[ ] TODO --> Изменить все книги в txt и выполнить действия над всеми
[ ] TODO --> Поиск по тексту и вывод страницы

Плюсы
- Неплохой парсинг текста
Минусы
- Делается вручную
- Слова с новой строки
- Метка на новой страници без нумерации 
- Нужно исправить метку на номер страници и тег

